"""
æ·˜å®æ¯å©´æ•°æ®æ¸…æ´—ä¸åˆ†æè„šæœ¬
ä½œè€…: å®‰å¾½å¤§å­¦ 23çº§äº’è”ç½‘é‡‘èä¸“ä¸š
æ—¥æœŸ: 2026å¹´
"""

import pandas as pd
import mysql.connector
from mysql.connector import Error
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

# ==================== æ•°æ®åº“è¿æ¥éƒ¨åˆ† ====================
def create_db_connection():
    """åˆ›å»ºæ•°æ®åº“è¿æ¥"""
    try:
        connection = mysql.connector.connect(
            host="localhost",
            user="lanlala",  
            password="197312zjf.",  
            database="test"  
        )
        print("æ•°æ®åº“è¿æ¥æˆåŠŸ!")
        return connection
    except Error as e:
        print(f"è¿æ¥å¤±è´¥: {e}")
        return None

# ==================== æ•°æ®æ¢ç´¢éƒ¨åˆ† ====================
def show_tables(connection):
    """æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„æ‰€æœ‰è¡¨"""
    cursor = connection.cursor()
    cursor.execute("SHOW TABLES")
    tables = cursor.fetchall()
    print("æ•°æ®åº“ä¸­çš„è¡¨ï¼š")
    for table in tables:
        print(f"- {table[0]}")
    cursor.close()
    return tables

def describe_table(connection, table_name):
    """æ˜¾ç¤ºè¡¨ç»“æ„"""
    cursor = connection.cursor()
    try:
        cursor.execute(f"DESCRIBE `{table_name}`")
        columns = cursor.fetchall()
        print(f"\nè¡¨ '{table_name}' çš„ç»“æ„ï¼š")
        print("=" * 60)
        for col in columns:
            print(f"å­—æ®µå: {col[0]:20} ç±»å‹: {col[1]:20} æ˜¯å¦ä¸ºç©º: {col[2]}")
        print("=" * 60)
    except Error as e:
        print(f"æŸ¥çœ‹è¡¨ç»“æ„å¤±è´¥ï¼š{e}")
    finally:
        cursor.close()

def load_data_to_dataframe(connection, table_name, limit=None):
    """ä»æ•°æ®åº“è¡¨è¯»å–æ•°æ®åˆ°Pandas DataFrame"""
    if limit:
        query = f"SELECT * FROM `{table_name}` LIMIT {limit}"
    else:
        query = f"SELECT * FROM `{table_name}`"
    
    try:
        df = pd.read_sql(query, connection)
        print(f"æˆåŠŸè¯»å– {len(df)} è¡Œæ•°æ®")
        return df
    except Exception as e:
        print(f"pd.read_sqlè¯»å–å¤±è´¥: {e}")
        print("å°è¯•ä½¿ç”¨cursor.fetchall()æ–¹æ³•...")
        
        try:
            cursor = connection.cursor()
            cursor.execute(query)
            columns = [desc[0] for desc in cursor.description]
            data = cursor.fetchall()
            df = pd.DataFrame(data, columns=columns)
            print(f"cursoræ–¹æ³•æˆåŠŸè¯»å– {len(df)} è¡Œæ•°æ®")
            return df
        except Exception as e2:
            print(f"ä¸¤ç§è¯»å–æ–¹æ³•éƒ½å¤±è´¥: {e2}")
            return None

# ==================== æ•°æ®è´¨é‡æ£€æŸ¥ ====================
def check_data_quality(df):
    """æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š"""
    print("=" * 60)
    print("æ•°æ®è´¨é‡æ£€æŸ¥æŠ¥å‘Š")
    print("=" * 60)
    
    if df is None or len(df) == 0:
        print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œæ£€æŸ¥")
        return None
    
    # 1. æ£€æŸ¥ç¼ºå¤±å€¼
    print("\n1. ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_values = df.isnull().sum()
    missing_percent = (missing_values / len(df)) * 100
    
    missing_df = pd.DataFrame({
        'ç¼ºå¤±æ•°é‡': missing_values,
        'ç¼ºå¤±ç™¾åˆ†æ¯”': missing_percent
    })
    
    if missing_df['ç¼ºå¤±æ•°é‡'].sum() == 0:
        print("æ²¡æœ‰ç¼ºå¤±å€¼!")
    else:
        print(missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0])
    
    # 2. æ£€æŸ¥é‡å¤è¡Œ
    print(f"\n2. é‡å¤è¡Œæ£€æŸ¥:")
    duplicates = df.duplicated().sum()
    print(f" é‡å¤è¡Œæ•°: {duplicates}")
    if duplicates == 0:
        print("æ²¡æœ‰å®Œå…¨é‡å¤çš„è¡Œ!")
    
    # 3. æ•°æ®ç»Ÿè®¡æ‘˜è¦ï¼ˆæ•°å€¼å‹ï¼‰
    print("\n3. æ•°å€¼å‹åˆ—ç»Ÿè®¡æ‘˜è¦:")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print(df[numeric_cols].describe())
    else:
        print("æ²¡æœ‰æ•°å€¼å‹åˆ—")
    
    # 4. ç±»åˆ«å‹åˆ—å”¯ä¸€å€¼æ•°é‡
    print("\n4. ç±»åˆ«å‹åˆ—å”¯ä¸€å€¼ç»Ÿè®¡:")
    categorical_cols = df.select_dtypes(include=['object']).columns
    for col in categorical_cols:
        unique_count = df[col].nunique()
        print(f"   {col}: {unique_count} ä¸ªå”¯ä¸€å€¼")
        if unique_count < 20 and unique_count > 0:
            print(f"     å…·ä½“å€¼: {df[col].unique()[:10]}")
    
    return missing_df

# ==================== æ•°æ®æ¸…æ´—å‡½æ•° ====================
def clean_taobao_data(df, missing_info):
    """æ·˜å®æ•°æ®ä¸“é¡¹æ¸…æ´—å‡½æ•° - é€‚é…å½“å‰è¡¨ç»“æ„"""
    print("=" * 60)
    print("å¼€å§‹ä¸“é¡¹æ•°æ®æ¸…æ´—")
    print("=" * 60)
    
    if df is None or len(df) == 0:
        print("æ•°æ®ä¸ºç©ºï¼Œæ— æ³•æ¸…æ´—")
        return None
    
    df_clean = df.copy()
    original_shape = df_clean.shape
    changes_log = []
    
    # 1. å¤„ç†ç¼ºå¤±å€¼
    for column in df_clean.columns:
        missing_count = df_clean[column].isnull().sum()
        if missing_count > 0:
            missing_percent = (missing_count / len(df_clean)) * 100
            
            if missing_percent > 30:
                df_clean.drop(column, axis=1, inplace=True)
                changes_log.append(f"åˆ é™¤åˆ— '{column}' (ç¼ºå¤±ç‡ {missing_percent:.1f}%)")
            elif missing_percent > 0:
                # ç‰¹æ®Šå¤„ç†user_idï¼ˆæ–‡æœ¬å‹ï¼‰
                if column == 'user_id':
                    if not df_clean[column].mode().empty:
                        fill_value = str(df_clean[column].mode()[0])
                    else:
                        fill_value = "unknown_user"
                    df_clean[column].fillna(fill_value, inplace=True)
                    changes_log.append(f"åˆ— '{column}': ç”¨ '{fill_value}' å¡«å…… {missing_count} ä¸ªç¼ºå¤±å€¼")
                # æ•°å€¼å‹åˆ—
                elif df_clean[column].dtype in ['int64', 'float64', 'int32', 'float32', 'int']:
                    fill_value = df_clean[column].median()
                    df_clean[column].fillna(fill_value, inplace=True)
                    changes_log.append(f"åˆ— '{column}': ç”¨ä¸­ä½æ•° {fill_value} å¡«å…… {missing_count} ä¸ªç¼ºå¤±å€¼")
                # å…¶ä»–æ–‡æœ¬å‹åˆ—
                else:
                    if not df_clean[column].mode().empty:
                        fill_value = df_clean[column].mode()[0]
                    else:
                        fill_value = "Unknown"
                    df_clean[column].fillna(fill_value, inplace=True)
                    changes_log.append(f"åˆ— '{column}': ç”¨ '{fill_value}' å¡«å…… {missing_count} ä¸ªç¼ºå¤±å€¼")
    
    
    # 2. å»é™¤å®Œå…¨é‡å¤çš„è¡Œ
    duplicates_before = df_clean.duplicated().sum()
    if duplicates_before > 0:
        df_clean.drop_duplicates(inplace=True)
        changes_log.append(f"åˆ é™¤ {duplicates_before} ä¸ªå®Œå…¨é‡å¤çš„è¡Œ")
    
    # 3. ä¸“é¡¹æ¸…æ´—ï¼šdayåˆ—æ ¼å¼è½¬æ¢
    if 'day' in df_clean.columns:
        try:
            df_clean['day'] = pd.to_datetime(df_clean['day'].astype(str), format='%Y%m%d', errors='coerce')
            invalid_dates = df_clean['day'].isnull().sum()
            if invalid_dates > 0:
                changes_log.append(f"'day'åˆ—ä¸­æœ‰ {invalid_dates} ä¸ªæ— æ•ˆæ—¥æœŸï¼Œå·²è®¾ä¸ºNaT")
        except Exception as e:
            changes_log.append(f"'day'åˆ—è½¬æ¢å¤±è´¥: {e}")
    
    # 4. ä¸“é¡¹æ¸…æ´—ï¼šbuy_mountåˆ—åˆç†æ€§æ£€æŸ¥
    if 'buy_mount' in df_clean.columns:
        try:
            df_clean['buy_mount'] = pd.to_numeric(df_clean['buy_mount'], errors='coerce')
            invalid_buy = df_clean[df_clean['buy_mount'] <= 0].shape[0]
            if invalid_buy > 0:
                changes_log.append(f"'buy_mount'åˆ—ä¸­æœ‰ {invalid_buy} ä¸ªéæ­£å€¼ï¼ˆâ‰¤0ï¼‰")
        except:
            pass
    
    # 5. ä¸“é¡¹æ¸…æ´—ï¼špropertyåˆ—å¤„ç†
    if 'property' in df_clean.columns:
        # æå–ç¬¬ä¸€ä¸ªå±æ€§é”®
        def extract_first_property(prop):
            if pd.isna(prop) or prop == "" or not isinstance(prop, str):
                return None
            if ":" in prop and ";" in prop:
                parts = str(prop).split(';')
                for part in parts:
                    if part and ':' in part:
                        return part.split(':')[0]
            return None
        
        df_clean['first_property_key'] = df_clean['property'].apply(extract_first_property)
        changes_log.append(f"ä»'property'åˆ—æå–é¦–å±æ€§é”®ï¼Œå…±æœ‰ {df_clean['first_property_key'].nunique()} ä¸ªå”¯ä¸€é”®")
    
    # 6. é‡ç½®ç´¢å¼•
    df_clean.reset_index(drop=True, inplace=True)
    
    # 7. è®°å½•æ¸…æ´—ç»“æœ
    print(f"\nä¸“é¡¹æ¸…æ´—å®Œæˆ!")
    print(f"   åŸå§‹æ•°æ®å½¢çŠ¶: {original_shape}")
    print(f"   æ¸…æ´—åå½¢çŠ¶: {df_clean.shape}")
    print(f"   åˆ é™¤äº† {original_shape[0] - df_clean.shape[0]} è¡Œ")
    print(f"   åˆ é™¤äº† {original_shape[1] - df_clean.shape[1]} åˆ—")
    
    if changes_log:
        print("\næ¸…æ´—æ“ä½œè®°å½•:")
        for log in changes_log:
            print(f"   â€¢ {log}")
    
    return df_clean, changes_log

# ==================== ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š ====================
def generate_cleaning_report(df_original, df_cleaned, changes_log, report_filename="data_cleaning_report.txt"):
    """ç”Ÿæˆæ•°æ®æ¸…æ´—æŠ¥å‘Š"""
    with open(report_filename, 'w', encoding='utf-8') as f:
        f.write("=" * 70 + "\n")
        f.write("æ·˜å®æ¯å©´æ•°æ®æ¸…æ´—æŠ¥å‘Š\n")
        f.write("=" * 70 + "\n\n")
        
        f.write(f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("1. æ•°æ®é›†æ¦‚è§ˆ\n")
        f.write("   " + "=" * 40 + "\n")
        f.write(f"   åŸå§‹æ•°æ®: {df_original.shape[0]} è¡Œ, {df_original.shape[1]} åˆ—\n")
        f.write(f"   æ¸…æ´—åæ•°æ®: {df_cleaned.shape[0]} è¡Œ, {df_cleaned.shape[1]} åˆ—\n")
        f.write(f"   æ•°æ®å‡å°‘: {df_original.shape[0] - df_cleaned.shape[0]} è¡Œ ({((df_original.shape[0] - df_cleaned.shape[0])/df_original.shape[0]*100):.1f}%)\n\n")
        
        f.write("2. æ¸…æ´—å‰åå­—æ®µå¯¹æ¯”\n")
        f.write("   " + "=" * 40 + "\n")
        f.write(f"   åŸå§‹å­—æ®µ: {list(df_original.columns)}\n")
        f.write(f"   æ¸…æ´—åå­—æ®µ: {list(df_cleaned.columns)}\n")
        f.write(f"   æ–°å¢å­—æ®µ: {[col for col in df_cleaned.columns if col not in df_original.columns]}\n\n")
        
        f.write("3. æ•°æ®æ¸…æ´—æ­¥éª¤\n")
        f.write("   " + "=" * 40 + "\n")
        for i, log in enumerate(changes_log, 1):
            f.write(f"   {i}. {log}\n")
        
        f.write("\n4. æ¸…æ´—æ•ˆæœéªŒè¯\n")
        f.write("   " + "=" * 40 + "\n")
        
        # ç¼ºå¤±å€¼å¯¹æ¯”
        original_missing = df_original.isnull().sum().sum()
        cleaned_missing = df_cleaned.isnull().sum().sum()
        f.write(f"   ç¼ºå¤±å€¼å¤„ç†: ä» {original_missing} å‡å°‘åˆ° {cleaned_missing}\n")
        
        # é‡å¤å€¼å¯¹æ¯”
        original_duplicates = df_original.duplicated().sum()
        cleaned_duplicates = df_cleaned.duplicated().sum()
        f.write(f"   é‡å¤è¡Œå¤„ç†: ä» {original_duplicates} å‡å°‘åˆ° {cleaned_duplicates}\n")
        
        f.write("\n5. å»ºè®®\n")
        f.write("   " + "=" * 40 + "\n")
        f.write("   â€¢ æ¸…æ´—åçš„æ•°æ®å·²å¯ç”¨äºè¿›ä¸€æ­¥åˆ†æ\n")
        f.write("   â€¢ å»ºè®®å¯¹first_property_keyè¿›è¡Œç¼–ç ä»¥ä¾¿åç»­å»ºæ¨¡\n")
        f.write("   â€¢ å¯å¯¹dayåˆ—è¿›è¡Œæ—¶é—´åºåˆ—åˆ†æ\n")
        f.write("   â€¢ å¯å¯¹buy_mountè¿›è¡Œåˆ†ç»„åˆ†æ\n")
    
    print(f"æ¸…æ´—æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_filename}")
    return report_filename

# ==================== ä¿å­˜æ¸…æ´—åæ•°æ® ====================
def save_cleaned_data(df_cleaned, conn, new_table_name="cleaned_taobao_data"):
    """å°†æ¸…æ´—åçš„æ•°æ®ä¿å­˜å›æ•°æ®åº“"""
    try:
        from sqlalchemy import create_engine
        
        # åˆ›å»ºè¿æ¥å­—ç¬¦ä¸²
        engine = create_engine('mysql+mysqlconnector://lanlala:197312zjf.@localhost/test')
        
        # ä¿å­˜åˆ°æ–°è¡¨
        df_cleaned.to_sql(new_table_name, engine, if_exists='replace', index=False)
        print(f"æ¸…æ´—åæ•°æ®å·²ä¿å­˜åˆ°æ–°è¡¨ '{new_table_name}'")
        return True
    except ImportError:
        print("æœªå®‰è£…sqlalchemyï¼Œæ— æ³•ä¿å­˜åˆ°æ•°æ®åº“")
        print("æ­£åœ¨ä¿å­˜ä¸ºCSVæ–‡ä»¶...")
        df_cleaned.to_csv("cleaned_taobao_data.csv", index=False, encoding='utf-8-sig')
        print("æ¸…æ´—åæ•°æ®å·²ä¿å­˜ä¸º 'cleaned_taobao_data.csv'")
        return False
    except Exception as e:
        print(f"ä¿å­˜å¤±è´¥: {e}")
        return False

# ==================== ä¸»ç¨‹åº ====================
def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("å¼€å§‹æ·˜å®æ¯å©´æ•°æ®æ¸…æ´—é¡¹ç›®")
    print("=" * 60)
    
    # 1. å»ºç«‹æ•°æ®åº“è¿æ¥
    conn = create_db_connection()
    if conn is None:
        return
    
    try:
        # 2. æ˜¾ç¤ºæ•°æ®åº“ä¸­çš„è¡¨
        tables = show_tables(conn)
        
        if not tables:
            print(" æ•°æ®åº“ä¸­æ²¡æœ‰è¡¨")
            return
        
        # 3. è·å–è¡¨å
        actual_table_name = tables[0][0]
        print(f"\næ£€æµ‹åˆ°çš„è¡¨å: {actual_table_name}")
        
        # 4. æ˜¾ç¤ºè¡¨ç»“æ„
        describe_table(conn, actual_table_name)
        
        # 5. è¯»å–æ•°æ®
        print("\næ­£åœ¨è¯»å–æ•°æ®...")
        df = load_data_to_dataframe(conn, actual_table_name, limit=1000)  # å…ˆè¯»1000è¡Œæµ‹è¯•
        
        if df is None or len(df) == 0:
            print("æ— æ³•è¯»å–æ•°æ®ï¼Œè¯·æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ä¸”åŒ…å«æ•°æ®")
            return
        
        # 6. æ˜¾ç¤ºæ•°æ®é¢„è§ˆ
        print("\næ•°æ®é¢„è§ˆ (å‰5è¡Œ):")
        print(df.head())
        print(f"\næ•°æ®åŸºæœ¬ä¿¡æ¯:")
        print(f"   æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"   åˆ—å: {list(df.columns)}")
        
        # 7. æ•°æ®è´¨é‡æ£€æŸ¥
        print("\n" + "=" * 60)
        missing_info = check_data_quality(df)
        
        # 8. æ•°æ®æ¸…æ´—
        print("\n" + "=" * 60)
        df_cleaned, changes_log = clean_taobao_data(df, missing_info)
        
        if df_cleaned is not None and len(df_cleaned) > 0:
            # 9. æ¸…æ´—åè´¨é‡æ£€æŸ¥
            print("\n" + "=" * 60)
            print("æ¸…æ´—åæ•°æ®è´¨é‡å¤æŸ¥")
            print("=" * 60)
            check_data_quality(df_cleaned)
            
            # 10. ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š
            print("\n" + "=" * 60)
            report_file = generate_cleaning_report(df, df_cleaned, changes_log)
            
            # 11. ä¿å­˜æ¸…æ´—åæ•°æ®
            print("\n" + "=" * 60)
            save_cleaned_data(df_cleaned, conn)
            
            print("\næ•°æ®æ¸…æ´—é¡¹ç›®å®Œæˆ!")
            print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
            print("   1. æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®æ¸…æ´—æŠ¥å‘Š")
            print("   2. å¯¹æ¸…æ´—åçš„æ•°æ®è¿›è¡Œæ¢ç´¢æ€§åˆ†æ")
            print("   3. è€ƒè™‘å°†ç»“æœä¸Šä¼ åˆ°GitHubä½œä¸ºé¡¹ç›®å±•ç¤º")
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        if conn.is_connected():
            conn.close()
            print("\næ•°æ®åº“è¿æ¥å·²å…³é—­")

# ==================== ç¨‹åºå…¥å£ ====================
if __name__ == "__main__":
    main()